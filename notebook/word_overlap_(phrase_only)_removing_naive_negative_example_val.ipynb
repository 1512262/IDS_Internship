{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_iou(x, y):\n",
    "    x = set(x.split('+'))\n",
    "    y = set(y.split('+'))\n",
    "    inter = x.intersection(y)\n",
    "    union = x.union(y)\n",
    "    iou = len(inter) / len(union)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80813, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_link = './NLP_data/data_AAAI/phrase_pair_val.csv'\n",
    "df_train = pd.read_csv(data_train_link,index_col=0)\n",
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ious = []\n",
    "for _, row in df_train.iterrows():\n",
    "    p_iou = lang_iou(row.phrase1, row.phrase2)\n",
    "    p_ious.append(p_iou)\n",
    "\n",
    "df_train['p_ious'] = np.asarray(p_ious)\n",
    "ious = list(set(df_train.p_ious.tolist())) \n",
    "ious.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 5111 68122\n",
      "0.1111111111111111 : 1 2\n",
      "0.125 : 4 7\n",
      "0.14285714285714285 : 15 24\n",
      "0.16666666666666666 : 52 50\n",
      "0.2 : 161 174\n",
      "0.25 : 604 366\n",
      "0.2857142857142857 : 3 1\n",
      "0.3333333333333333 : 1665 672\n",
      "0.4 : 50 22\n",
      "0.42857142857142855 : 2 1\n",
      "0.5 : 2591 534\n",
      "0.5714285714285714 : 3 1\n",
      "0.6 : 11 0\n",
      "0.6666666666666666 : 451 60\n",
      "0.75 : 38 3\n",
      "0.8333333333333334 : 1 0\n",
      "1.0 : 10 1\n"
     ]
    }
   ],
   "source": [
    "for iou in ious:\n",
    "    len_true = len(df_train[(df_train.p_ious==iou)&(df_train.ytrue==True)].ytrue.tolist())\n",
    "    len_false = len(df_train[(df_train.p_ious==iou)&(df_train.ytrue==False)].ytrue.tolist())\n",
    "    print(iou,\":\",len_true,len_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iou in ious:\n",
    "    len_true = len(df_train[(df_train.p_ious==iou)&(df_train.ytrue==True)].ytrue.tolist())\n",
    "    len_false = len(df_train[(df_train.p_ious==iou)&(df_train.ytrue==False)].ytrue.tolist())\n",
    "    index_True= df_train[(df_train.p_ious==iou)&(df_train.ytrue==True)].index.tolist()\n",
    "    index_False = df_train[(df_train.p_ious==iou)&(df_train.ytrue==False)].index.tolist()\n",
    "    n_drop = abs(len_false-len_true)\n",
    "    flag = True\n",
    "    if(len_true>len_false):\n",
    "        index= index_True\n",
    "    else:\n",
    "        index = index_False\n",
    "        flag = False\n",
    "    \n",
    "    drop_indices = np.random.choice(index, n_drop, replace=False)\n",
    "    df_train=df_train.drop(drop_indices)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 5111 5111\n",
      "0.1111111111111111 : 1 1\n",
      "0.125 : 4 4\n",
      "0.14285714285714285 : 15 15\n",
      "0.16666666666666666 : 50 50\n",
      "0.2 : 161 161\n",
      "0.25 : 366 366\n",
      "0.2857142857142857 : 1 1\n",
      "0.3333333333333333 : 672 672\n",
      "0.4 : 22 22\n",
      "0.42857142857142855 : 1 1\n",
      "0.5 : 534 534\n",
      "0.5714285714285714 : 1 1\n",
      "0.6 : 0 0\n",
      "0.6666666666666666 : 60 60\n",
      "0.75 : 3 3\n",
      "0.8333333333333334 : 0 0\n",
      "1.0 : 1 1\n"
     ]
    }
   ],
   "source": [
    "for iou in ious:\n",
    "    len_true = len(df_train[(df_train.p_ious==iou)&(df_train.ytrue==True)].ytrue.tolist())\n",
    "    len_false = len(df_train[(df_train.p_ious==iou)&(df_train.ytrue==False)].ytrue.tolist())\n",
    "    print(iou,\":\",len_true,len_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14006, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_train = shuffle(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.sort_values(by=['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"new_phrase_pair_val.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
